<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="/"/>
    <title>Colloquium II - Paper</title>

    <meta name="generator" content="pandoc" />
        
    <link rel="stylesheet" href="/files/template/archive.css">

</head>
<body>

    <nav role="navigation">
        <a target="_self" href="/">Home</a>
        
        <ul class="nav-h">
	        <li><a target="_self" href="/pages/journal.html">Journal</a></li>
	        <li><a target="_self" href="/pages/texts-and-talks.html">Texts and Talks</a></li>
	        <li><a target="_self" href="/pages/notes.html">Notes</a></li>
	        <li><a target="_self" href="/fp1/index.html">Fallow Zine 1</a></li>
        </ul>

    </nav>

    <main role="main">
        <h1 id="things-are-people-too">Things Are People Too</h1>
        <h2
        id="negotiating-privacy-with-voice-assistants---an-analysis-of-our-relationship-to-the-internet-of-things">Negotiating
        privacy with voice assistants - An analysis of our relationship
        to the internet of things</h2>
        <p>The internet of things, IoT for short, consists of things
        that talk to each other through the help of sensors, software,
        and data exchanges. Voice-activated interfaces, as seen in voice
        assistants devices like the Amazon Echo, are a highly humanized
        way of interacting with the internet of things.</p>
        <p>Despite building on a very human way of interaction, namely
        oral communication, there are many issues to be found in this
        approach to interface design as this research project uncovered.
        I argue that these problems can’t be solved by improving the
        technology alone, but that they also stem from being a
        specifically disembodied implementation of interaction and thus
        need to be improved through the approach of user experience
        design.</p>
        <p>Originally this project was interested in introducing
        animistic practices, as they are found in non-western
        epistemologies <span class="citation"
        data-cites="guthTheorizingHariKuyo2014">[@guthTheorizingHariKuyo2014]</span>,
        into the interaction with everyday technologies<a href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn1"
        class="footnote-ref" id="fnref1"
        role="doc-noteref"><sup>1</sup></a>. As the ethnographic
        research done during the last year could not unearth substantial
        material to back up this initial approach, the hypothesis as
        well as the accompanying research questions needed to be
        reassessed.</p>
        <p>This paper is accompanied by a presentation to be held in
        June 2021, which will expand on the findings, the underlying
        framework as well as the concept behind the upcoming phase of
        prototyping. I also invite you to explore the research blog
        which contains personal insights, through the endnotes in this
        paper.</p>
        <h2 id="process">Process</h2>
        <p>During the data gathering process, I was mainly interested in
        the emotional bond between users and their voice assistants. How
        these bonds form, what enables them, how they are present in the
        interaction and behaviors. I found guidance for this approach in
        emotionally durable design by Jonathan Chapman, a practical
        framework that is used in industrial design <span
        class="citation"
        data-cites="haines-gaddEmotionalDurabilityDesign2018">[@haines-gaddEmotionalDurabilityDesign2018]</span>.
        The second important point was the capturing of weak signals.
        These are a concept from speculative or future design and can be
        thought of as micro trends. The weak signals, pain points but
        also memorable experiences, would go into the prototyping of a
        voice assistant that improves on the current implementations on
        the market, according to the values formulated by this
        project.</p>
        <p>I gathered insights and data from three different main
        sources. I led interviews<a href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn2" class="footnote-ref"
        id="fnref2" role="doc-noteref"><sup>2</sup></a> with owners of
        voice assistants and could conduct around 25 hours of
        participatory observation<a href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn3" class="footnote-ref"
        id="fnref3" role="doc-noteref"><sup>3</sup></a> of interaction,
        as well as a handful of unboxing and setup user journeys<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn4" class="footnote-ref" id="fnref4"
        role="doc-noteref"><sup>4</sup></a>. The second source was user
        experience reports that owners of voice assistants posted
        online. I also researched the image worlds of hacked and
        customized devices as well as the advertisement created by the
        brands, although these two assets were not considered in the
        analysis of the data.</p>
        <p>The third and last source of insights was collected through
        an expert workshop with designers from different disciplines. I
        wanted to have the opinion of specialists in their respective
        areas on how to improve the emotional bond between users and
        their voice assistant devices. The workshop was based on the
        emotional durable design framework as well as the collected
        data. The methodology of the framework oriented itself along the
        lines of speculative design. I wanted to push the participating
        designers towards imagining alternative ways of interacting or
        deploying voice user interfaces.<a href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn5"
        class="footnote-ref" id="fnref5"
        role="doc-noteref"><sup>5</sup></a></p>
        <p>All the recordings and field notes were transcribed,
        anonymized, and pushed into a public archive, together with
        other media, like photos or documents. To work with the
        collected data I opted for thematic analysis, with a reflexive
        approach after Braun and Clarke. This is a rather classical
        qualitative data analysis approach that labels the transcribed
        data and then builds overarching themes out of the codes.</p>
        <blockquote>
        <p>The reflexivity process can be described as the researcher
        reflecting on and documenting how their values, positionings,
        choices, and research practices influenced and shaped the study
        and the final analysis of the data. <span class="citation"
        data-cites="braunThematicAnalysis2019">[@braunThematicAnalysis2019]</span></p>
        </blockquote>
        <p>I went for this approach, as it felt intuitive and spoke to
        me in terms of my values as research as an embodied practice.
        Themes do not emerge passively out of the data by themselves but
        are actively created by me, the researching person. <a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn6" class="footnote-ref" id="fnref6"
        role="doc-noteref"><sup>6</sup></a> <a href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn7"
        class="footnote-ref" id="fnref7"
        role="doc-noteref"><sup>7</sup></a></p>
        <p>Next to the fieldwork and the thematic analysis, I had an
        ongoing process of literature study, exchange with scholars from
        the field of design theory as well as an attempt to formulate an
        underlying framework upon which I could base the prototyping
        phase. Within this process I was able to present my project at
        two different conferences; Reclaim Futures in September 2020<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn8" class="footnote-ref" id="fnref8"
        role="doc-noteref"><sup>8</sup></a> and the very giving NERD in
        June 2021<a href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn9" class="footnote-ref" id="fnref9"
        role="doc-noteref"><sup>9</sup></a>.</p>
        <h2 id="findings">Findings</h2>
        <p>The reassessed hypothesis presented at the beginning of this
        paper is based on the thematic analysis as well as direct
        insights by my participants. Through the process of analysis, I
        could read two main themes out of the collected data. <a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn10" class="footnote-ref" id="fnref10"
        role="doc-noteref"><sup>10</sup></a></p>
        <h3 id="uncanny-valley">Uncanny Valley</h3>
        <p>The first theme can be subsumed under the concept of the
        uncanny valley. This is a psychological effect in which the more
        a thing is perceived as human the more trustworthy or relatable
        it is. In this linear progress, there is a brief gap of
        cognitive dissonance when we can’t decide anymore if something
        is human or not. This gap is the uncanny valley, and we
        generally don’t trust things if they are to be placed in there.
        <span class="citation"
        data-cites="moriUncannyValley2012">[@moriUncannyValley2012]</span></p>
        <p>The uncanny valley finds many expressions in the interaction
        with voice assistants. First, we have <strong>uncanny
        communication</strong> by encountering human voices but robotic
        speech patterns. The voices of current implements are near
        perfect, indistinguishable from real humans, but the way they
        communicate is perceived as robotic or scripted.</p>
        <p>Another often encountered problem is that the devices go off
        without users intending them to do so; <strong>activation
        without interaction</strong>. I have more than one funny and
        sometimes downwards creepy anecdote to tell around this. These
        seemingly random activations are often not perceived as quirky,
        like with a pet, but alienating.</p>
        <p>The last issue is that voice assistants build up a
        <strong>ghostly presence</strong>. This perception arises from
        the fact, that voice assistants are always-on devices. They are
        always listening in on their environment, waiting for a wake
        word. Upon hearing which they unlock and are available for
        further interaction. Knowing this made my participants feel a
        presence in the room that led them to alter their behaviors and
        how they spoke.</p>
        <h3 id="trust-issues">Trust Issues</h3>
        <p>The second theme covers trust issues, that my participants
        had with their voice assistants. This theme can be broken down
        into <strong>issues with privacy, intimacy, and
        consent</strong>.</p>
        <p>The problems around <strong>privacy</strong> hover mainly
        around the data tracking habits of issuing companies like Google
        or Amazon. Most of my participants were acutely aware of these
        practices. They either took this as the price they have to pay
        or were considering changing providers if a privacy-sensitive
        alternative would exist.</p>
        <p>Generally, these devices are placed within intimate contexts
        of one’s own life. On the other hand, voice assistants are
        invisible interfaces that withdraw from the negotiation of
        <strong>intimacy</strong>. This withdrawal is partially intended
        by the manufactures, argues Adam Greenfield <span
        class="citation"
        data-cites="greenfieldRadicalTechnologiesDesign2018">[@greenfieldRadicalTechnologiesDesign2018]</span>,
        in order for the devices to colonize our homes. The problem
        boils down to us inviting these devices into our innermost
        intimacies, while not offering anything similar in return.</p>
        <p>Adding to these two points is the fact, that users have
        little to no control over how they want to interact with the
        voice assistants. Users have no way of giving
        <strong>consent</strong> to many of the processes that are run
        by the device.</p>
        <p>The general problem that arises out of these two themes would
        then be as follows.</p>
        <blockquote>
        <p>Users of voice assistants miss a proper vocabulary to deal
        with the other-than-human presence, especially in case of
        errors, and generally have a hard time bonding with voice
        assistants. They are further unable to deal with issues of trust
        and can assert only little control over the negotiation of these
        important aspects.</p>
        </blockquote>
        <p>It seems that neither the user nor the device knows enough
        about the other to enable communication and interaction that
        would lead to trust and bonding. The interaction with a voice
        assistant needs to feature implementations of design
        characteristics, that enables the user to not just tolerate but
        embrace the chaotic nature of voice assistants while still being
        to unlock their full potential.</p>
        <h2 id="implications-and-outlook">Implications and Outlook</h2>
        <p>After the thematic analysis, I had to come to terms with the
        fact that I was not able to continue with the original
        hypothesis and research question<a href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn11"
        class="footnote-ref" id="fnref11"
        role="doc-noteref"><sup>11</sup></a>. The intended weak signals
        were nowhere to be found. Killing my darlings was half as wild,
        as the analysis unearthed ample material for further research. I
        decided to continue working on the second main theme,
        <strong>Trust Issues</strong><a href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fn12"
        class="footnote-ref" id="fnref12"
        role="doc-noteref"><sup>12</sup></a>.</p>
        <p>Based on the fieldwork done in the last two semesters as well
        as the literature review, the research now focuses on the
        particular problem of negotiating privacy with voice assistants.
        Communication between people relies on multiple modalities and
        is a multisensory process. Cues are exchanged, eye contact or
        body posture signalize attention, face and hands add intent. It
        seems that these cues are missing in the interaction with a
        voice assistant as it is reduced to just one modality, sound.
        Voice assistants simulate oral communication but are stripped of
        other channels of interaction. The hypothesis is given through
        the thematic analysis. My reformulated research question then
        would be as follows.</p>
        <blockquote>
        <p>How can we negotiate trust, respectively privacy, intimacy,
        and consent with internet of things devices like voice
        assistants?</p>
        </blockquote>
        <p>The insights I got from the users of voice assistants point
        to missing cues in the interaction and communication between
        them and their devices. What effects have the reintroduction of
        these cues, in regards for the negotiation of privacy between
        voice assistants and their users? How does a user journey of
        bonding and developing trust need to be designed? Additional
        cues could be a stronger visual representation of the state of
        the assistant to inform the user, as well as using touch,
        movement, or a beacon-object to signalize certain intents to
        inform the assistant.</p>
        <p>I would like to answer these questions from a user experience
        as well as an interaction design perspective. This is in part
        mirrored by the post-phenomenological approach to technology of
        D.E. Wittkower and Diane P. Michelfelder <span class="citation"
        data-cites="wiltseRelatingThingsDesign2020">[see
        @wiltseRelatingThingsDesign2020]</span>. In their contributions
        to Relating to Things, they look at our relationship to privacy
        as well as voice assistants from the perspective of human
        experience.</p>
        <p>The last phase of prototyping is guided, next to the findings
        of the analysis and insights so far, by design theory from
        Jonathan Chapman <span class="citation"
        data-cites="chapmanEmotionallyDurableDesign2015">[@chapmanEmotionallyDurableDesign2015]</span>
        and Betti Marenko <span class="citation"
        data-cites="marenkoAnimisticDesignHow2016">[@marenkoAnimisticDesignHow2016]</span>.
        Both developed their framework of parameters for the design of
        relatable technological artifacts that enable bonding and have
        overlaps in their approaches. I was able to cross-reference and
        validate these frameworks with studies done by them as well as
        others.</p>
        <p>I plan to use the last semester for designing user journeys
        that enable bonding and trust. Furthermore, I will implement and
        test these user journeys on a development platform for voice
        assistants, built on open-source technologies. In the last few
        weeks, I was able to set up this development platform as well as
        implement a handful of first experiences, that play with the
        aforementioned beacon objects but also with aspects from the
        guiding frameworks. The tests were successful in so far as
        showing that the approach would be feasible from a technical
        point of view.</p>
        <p>With this last problem out of the way, I am ready for the
        design and testing of the user journeys towards bonding and
        building trust with voice assistants.</p>
        <section id="footnotes"
        class="footnotes footnotes-end-of-document" role="doc-endnotes">
        <hr />
        <ol>
        <li id="fn1"><p>https://tapt.things.care/researchplan-2020<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref1" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li
        id="fn2"><p>https://tapt.things.care/interview-voice-assistant-basics<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref2" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li
        id="fn3"><p>https://tapt.things.care/participatory-observations<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref3" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li
        id="fn4"><p>https://tapt.things.care/unboxing-the-voice-assistants<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref4" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li id="fn5"><p>https://tapt.things.care/expert-workshop-i<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref5" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li id="fn6"><p>https://tapt.things.care/reflexive-journal-i<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref6" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li id="fn7"><p>https://tapt.things.care/reflexive-journal-ii<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref7" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li id="fn8"><p>https://tapt.things.care/reclaim-futures-2020<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref8" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li id="fn9"><p>https://tapt.things.care/nerd-2021<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref9" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li
        id="fn10"><p>https://tapt.things.care/finding-of-thematic-analysis<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref10" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li
        id="fn11"><p>https://tapt.things.care/crossroads-and-conjunctions<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref11" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        <li
        id="fn12"><p>https://tapt.things.care/review-semesters-iii-and-iv<a
        href="/text-and-talks/colloquium/II/Colloquium II - Paper.html#fnref12" class="footnote-back"
        role="doc-backlink">↩︎</a></p></li>
        </ol>
        </section>
    </main>

    <footer class="text-sm">
        <p class="flex">
            <a href="pages/about.html">About</a>
            &mdash;
            <a href="https://webring.xxiivv.com/#jachere" target="_blank">
                <img width="28" src="https://webring.xxiivv.com/icon.black.svg" alt="XXIIVV webring"/>
            </a>
        </p>
        <p>All content, where not noted otherwise on <a href="https://jache.re">jache.re</a> is released and distributed under the <a href="https://creativecommons.org/licenses/by/4.0/legalcode">CC-BY 4.0 license</a>.</p>
    </footer>
</body>
</html>
